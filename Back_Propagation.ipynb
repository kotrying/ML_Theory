{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3DCoPIXLS8Zdn3H/TpxgO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotrying/ML_Theory/blob/main/Back_Propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5E-Szxrc-L9C"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Back Propagation（誤差逆伝搬）の実装\n",
        "\n",
        "# 各層の初期化\n",
        "# クラスからインスタンス化する\n",
        "middle_layer = MiddleLayer(n_in, n_mid) # （入力層のニューロン数、中間層のニューロン数）を引数へ\n",
        "output_layer = OutputLayer(n_mid, n_out) # （中間層のニューロン数、出力層のニューロン数）を引数へ\n",
        "\n",
        "# 学習\n",
        "# エポック数分の学習を実行\n",
        "for i in range(epoch):\n",
        "    # 確率的勾配降下法を実施\n",
        "    # 入力データの数分の要素を持つインデックス行列を作成\n",
        "    index_random = np.arange(n_data) # n_data = len(input_data)\n",
        "    # インデックスをランダムにシャッフル\n",
        "    np.random.shuffle(index_random)\n",
        "    \n",
        "    # 結果の表示用：誤差、入力、出力を保存し、後で学習の結果を確認する\n",
        "    total_error = 0 # 誤差の初期値：各学習ステップで計算される入力と出力との誤差を加算\n",
        "    plot_x = [] # 各学習ステップごとに使用した入力\n",
        "    plot_y = [] # 各学習ステップごとに得られた出力\n",
        "    \n",
        "    # インデックス行列から順にインデックスを取り出す\n",
        "    for idx in index_random:\n",
        "        # 指定のインデックスに対応するデータをスライス(p50参照)で取り出す（バッチサイズは１）\n",
        "        x = input_data[idx:idx+1]  # 入力：指定のインデックスにおける入力データの値\n",
        "        t = correct_data[idx:idx+1]  # 正解：指定のインデックスにおける正解データの値\n",
        "        \n",
        "        # 順伝播\n",
        "        middle_layer.forward(x.reshape(1, 1)) # 入力を行列（行数１、列数１）に変換\n",
        "        output_layer.forward(middle_layer.y) # 中間層→出力層\n",
        "\n",
        "        # 逆伝播\n",
        "        output_layer.backward(t.reshape(1, 1))  # 正解を行列（行数１、列数１）に変換\n",
        "        middle_layer.backward(output_layer.grad_x) # 出力層→中間層\n",
        "        \n",
        "        # 重みとバイアスの更新\n",
        "        middle_layer.update(eta)\n",
        "        output_layer.update(eta)"
      ],
      "metadata": {
        "id": "jDMU2ayaQWYr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4xLYR7upPJL6"
      },
      "outputs": [],
      "source": [
        "# 中間層\n",
        "class MiddleLayer:\n",
        "    def __init__(self, n_upper, n, wb_width = 0.01):  # 初期設定\n",
        "        self.w = wb_width * np.random.randn(n_upper, n)  # 重み（行列）\n",
        "        self.b = wb_width * np.random.randn(n)  # バイアス（ベクトル）\n",
        "\n",
        "    def forward(self, x):  # 順伝播\n",
        "        self.x = x\n",
        "        u = np.dot(x, self.w) + self.b\n",
        "        self.y = 1/(1+np.exp(-u))  # シグモイド関数\n",
        "    \n",
        "    def backward(self, grad_y):  # 逆伝播\n",
        "        delta = grad_y * (1-self.y)*self.y  # シグモイド関数の微分\n",
        "        \n",
        "        self.grad_w = np.dot(self.x.T, delta)\n",
        "        self.grad_b = np.sum(delta, axis=0)\n",
        "        \n",
        "        self.grad_x = np.dot(delta, self.w.T) \n",
        "        \n",
        "    def update(self, eta):  # 重みとバイアスの更新\n",
        "        self.w -= eta * self.grad_w\n",
        "        self.b -= eta * self.grad_b\n",
        "\n",
        "# 出力層\n",
        "class OutputLayer:\n",
        "    def __init__(self, n_upper, n, wb_width = 0.01):  # 初期設定\n",
        "        self.w = wb_width * np.random.randn(n_upper, n)  # 重み（行列）\n",
        "        self.b = wb_width * np.random.randn(n)  # バイアス（ベクトル）\n",
        "    \n",
        "    def forward(self, x):  # 順伝播\n",
        "        self.x = x\n",
        "        u = np.dot(x, self.w) + self.b\n",
        "        self.y = u  # 恒等関数\n",
        "    \n",
        "    def backward(self, t):  # 逆伝播\n",
        "        delta = self.y - t\n",
        "        \n",
        "        self.grad_w = np.dot(self.x.T, delta)\n",
        "        self.grad_b = np.sum(delta, axis=0)\n",
        "        \n",
        "        self.grad_x = np.dot(delta, self.w.T) \n",
        "\n",
        "    def update(self, eta):  # 重みとバイアスの更新\n",
        "        self.w -= eta * self.grad_w\n",
        "        self.b -= eta * self.grad_b\n",
        "\n",
        "# Back Propagation（誤差逆伝搬）の実装\n",
        "def back_propagation(input_data: np.ndarray, correct_data: np.ndarray, n_in: int, n_mid: int, n_out: int, epoch: int, eta: int):\n",
        "\n",
        "    np.random.seed(181045)\n",
        "\n",
        "    # 各層の初期化\n",
        "    # クラスからインスタンス化する\n",
        "    middle_layer = MiddleLayer(n_in, n_mid) # （入力層のニューロン数、中間層のニューロン数）を引数へ\n",
        "    output_layer = OutputLayer(n_mid, n_out) # （中間層のニューロン数、出力層のニューロン数）を引数へ\n",
        "\n",
        "    n_data = len(input_data)\n",
        "\n",
        "    # 学習\n",
        "    # エポック数分の学習を実行\n",
        "    for i in range(epoch):\n",
        "        # 確率的勾配降下法を実施\n",
        "        # 入力データの数分の要素を持つインデックス行列を作成\n",
        "        index_random = np.arange(n_data)\n",
        "        # インデックスをランダムにシャッフル\n",
        "        np.random.shuffle(index_random)\n",
        "        \n",
        "        # 結果の表示用：誤差、入力、出力を保存し、後で学習の結果を確認する\n",
        "        total_error = 0 # 誤差の初期値：各学習ステップで計算される入力と出力との誤差を加算\n",
        "        plot_y = np.zeros((n_data, ), dtype=np.float32) # 各学習ステップごとに得られた出力\n",
        "        \n",
        "        # インデックス行列から順にインデックスを取り出す\n",
        "        for idx in index_random:\n",
        "            # 指定のインデックスに対応するデータをスライス(p50参照)で取り出す（バッチサイズは１）\n",
        "            x = input_data[idx:idx+1]  # 入力：指定のインデックスにおける入力データの値\n",
        "            t = correct_data[idx:idx+1]  # 正解：指定のインデックスにおける正解データの値\n",
        "            \n",
        "            # 順伝播\n",
        "            middle_layer.forward(x.reshape(1, 1)) # 入力を行列（行数１、列数１）に変換\n",
        "            output_layer.forward(middle_layer.y) # 中間層→出力層\n",
        "\n",
        "            # 逆伝播\n",
        "            output_layer.backward(t.reshape(1, 1))  # 正解を行列（行数１、列数１）に変換\n",
        "            middle_layer.backward(output_layer.grad_x) # 出力層→中間層\n",
        "            \n",
        "            # 重みとバイアスの更新\n",
        "            middle_layer.update(eta)\n",
        "            output_layer.update(eta)\n",
        "\n",
        "            if i%100==0:\n",
        "                plot_y[idx] = output_layer.y.reshape(-1)\n",
        "        if i%100==0:\n",
        "            print(f'- {i+1}回目の出力 : {plot_y}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力データ\n",
        "input_data = np.array([1,2,3,4,5])\n",
        "# 正解データ\n",
        "correct_data = np.array([2,4,6,8,10])\n",
        "# 実行\n",
        "back_propagation(input_data, correct_data, n_in=1, n_mid=3, n_out=1, epoch=1501, eta=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGdWX5WZpbP4",
        "outputId": "383e4cb5-1afb-4426-e744-0864954c5e72"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- 1回目の出力 : [0.71048784 0.01762506 5.0574017  0.93565327 2.5873468 ]\n",
            "- 101回目の出力 : [2.275919  3.378271  6.5474505 7.7531214 9.658143 ]\n",
            "- 201回目の出力 : [2.2071044 3.8314712 6.5546637 7.774943  9.593967 ]\n",
            "- 301回目の出力 : [2.3319213 3.3205817 6.295534  8.09365   9.657005 ]\n",
            "- 401回目の出力 : [2.2528434 3.6546729 6.4118514 7.913717  9.921646 ]\n",
            "- 501回目の出力 : [2.2949748 3.7310224 5.8647985 7.8433623 9.980521 ]\n",
            "- 601回目の出力 : [ 2.1274688  3.8599913  6.0777335  8.070919  10.32872  ]\n",
            "- 701回目の出力 : [2.045355 4.121908 5.59853  8.539867 9.631587]\n",
            "- 801回目の出力 : [2.0145957 3.9454331 5.873819  8.216927  9.877725 ]\n",
            "- 901回目の出力 : [1.9999776 4.0114007 5.9781847 8.005793  9.980517 ]\n",
            "- 1001回目の出力 : [1.9990685 3.9997993 5.94052   8.065308  9.977423 ]\n",
            "- 1101回目の出力 : [ 1.9999874  4.002497   5.998506   7.995465  10.004804 ]\n",
            "- 1201回目の出力 : [1.9998585 4.001294  6.001886  8.003889  9.99597  ]\n",
            "- 1301回目の出力 : [1.9996318 3.9999554 6.0005035 8.003841  9.994724 ]\n",
            "- 1401回目の出力 : [2.0000238 4.000538  5.9985824 8.001151  9.999988 ]\n",
            "- 1501回目の出力 : [ 2.0000355  4.000012   6.0000052  7.9996834 10.000387 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qnq8jlqmAeH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}